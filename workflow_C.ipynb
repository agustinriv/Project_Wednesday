{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cEmzeUKFkPh"
   },
   "source": [
    "# Wokflow con Full Bayesiana "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DenyKXkiJ5JN"
   },
   "source": [
    "##  Big Picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-01 13:37:57 EDT\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td> 649543</td><td>34.7</td><td>1439644</td><td>76.9</td><td>1245341</td><td>66.6</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>1206239</td><td> 9.3</td><td>8388608</td><td>64.0</td><td>1924957</td><td>14.7</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 6 of type dbl\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &  649543 & 34.7 & 1439644 & 76.9 & 1245341 & 66.6\\\\\n",
       "\tVcells & 1206239 &  9.3 & 8388608 & 64.0 & 1924957 & 14.7\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 6 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|\n",
       "| Ncells |  649543 | 34.7 | 1439644 | 76.9 | 1245341 | 66.6 |\n",
       "| Vcells | 1206239 |  9.3 | 8388608 | 64.0 | 1924957 | 14.7 |\n",
       "\n"
      ],
      "text/plain": [
       "       used    (Mb) gc trigger (Mb) max used (Mb)\n",
       "Ncells  649543 34.7 1439644    76.9 1245341  66.6\n",
       "Vcells 1206239  9.3 8388608    64.0 1924957  14.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# limpio la memoria\n",
    "Sys.time()\n",
    "rm(list=ls(all.names=TRUE)) # remove all objects\n",
    "gc(full=TRUE, verbose=FALSE) # garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "PARAM <- list()\n",
    "PARAM$experimento <- \"seg-001\"\n",
    "PARAM$semilla_primigenia <- 100343"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "setwd(\"/content/buckets/b1/exp\")\n",
    "experimento_folder <- PARAM$experimento\n",
    "dir.create(experimento_folder, showWarnings=FALSE)\n",
    "setwd( paste0(\"/content/buckets/b1/exp/\", experimento_folder ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dseB4qb9RqUb"
   },
   "source": [
    "### Traigo df ya modificado en workflow A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P863YZB9R1Ua",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-01 13:37:58 EDT\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: data.table\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td>   758257</td><td>  40.5</td><td>   1439644</td><td>  76.9</td><td>  1439644</td><td>  76.9</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>722128601</td><td>5509.5</td><td>1017371871</td><td>7762.0</td><td>845986738</td><td>6454.4</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 6 of type dbl\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &    758257 &   40.5 &    1439644 &   76.9 &   1439644 &   76.9\\\\\n",
       "\tVcells & 722128601 & 5509.5 & 1017371871 & 7762.0 & 845986738 & 6454.4\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 6 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|\n",
       "| Ncells |    758257 |   40.5 |    1439644 |   76.9 |   1439644 |   76.9 |\n",
       "| Vcells | 722128601 | 5509.5 | 1017371871 | 7762.0 | 845986738 | 6454.4 |\n",
       "\n"
      ],
      "text/plain": [
       "       used      (Mb)   gc trigger (Mb)   max used  (Mb)  \n",
       "Ncells    758257   40.5    1439644   76.9   1439644   76.9\n",
       "Vcells 722128601 5509.5 1017371871 7762.0 845986738 6454.4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-01 13:38:17 EDT\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(duckdb)\n",
    "setwd(\"~/Project_Wednesday\")\n",
    "\n",
    "con <- dbConnect(duckdb::duckdb(), dbdir=\":memory:\")\n",
    "dataset <- dbGetQuery(con, \"SELECT * FROM read_parquet('df.parquet')\")\n",
    "dbDisconnect(con)\n",
    "\n",
    "head(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# paso la clase a binaria que tome valores {0,1}  enteros\n",
    "#  BAJA+1 y BAJA+2  son  1,   CONTINUA es 0\n",
    "#  a partir de ahora ya NO puedo cortar  por prob(BAJA+2) > 1/40\n",
    "\n",
    "dataset[, clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\",\"BAJA+1\"), 1L, 0L)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace una estrategia de entrenamiento muy sencilla, tomando todos los meses posibles, SIN eliminar nada x pandemia ni por ningun otro motivo\n",
    "\n",
    "* future = 202108  obviamente completo\n",
    "\n",
    "* final_train =  [201901, 202106] sin undersampling de los CONTINUA\n",
    "\n",
    "* training\n",
    "   * testing = 202106\n",
    "   * training = [201901, 202104]  donde se consideran el 5% de los CONTINUA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "PARAM$trainingstrategy$testing <- c(202106)\n",
    "\n",
    "PARAM$trainingstrategy$training <- c(\n",
    "  202101, 202102, 202103, 202104\n",
    ")\n",
    "\n",
    "PARAM$trainingstrategy$undersampling <- 0.1\n",
    "\n",
    "\n",
    "PARAM$trainingstrategy$positivos <- c( \"BAJA+1\", \"BAJA+2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# los campos en los que se entrena\n",
    "campos_buenos <- copy( setdiff(\n",
    "    colnames(dataset), c(\"clase_ternaria\",\"clase01\",\"azar\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Registros  cambio las proporciones de POS/NEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Undersampling, van todos los \"BAJA+1\" y \"BAJA+2\" y solo algunos \"CONTINIA\"\n",
    "\n",
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
    "dataset[, azar := runif(nrow(dataset))]\n",
    "dataset[, training := 0L]\n",
    "\n",
    "dataset[  foto_mes %in%  PARAM$trainingstrategy$training &\n",
    "  (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
    "  training := 1L\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizacion de Hipeparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se optimizan los hiperparámetros maximizando la ganancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "if( !require(\"lightgbm\")) install.packages(\"lightgbm\")\n",
    "require(\"lightgbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filas 236042 columnas 1253 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-01 13:45:53 EDT\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dtrain <- lgb.Dataset(\n",
    "  data= data.matrix(dataset[training == 1L, campos_buenos, with = FALSE]),\n",
    "  label= dataset[training == 1L, clase01],\n",
    "  free_raw_data= TRUE\n",
    ")\n",
    "\n",
    "cat(\"filas\", nrow(dtrain), \"columnas\", ncol(dtrain), \"\\n\")\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filas 164313 columnas 1258 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-01 13:45:56 EDT\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# defino los datos de testing\n",
    "dataset_test <- dataset[foto_mes %in% PARAM$trainingstrategy$testing]\n",
    "\n",
    "# precalculo el campo de la ganancia\n",
    "dataset_test[, gan := -20000.0 ]\n",
    "dataset_test[ clase_ternaria==\"BAJA+2\", gan := 780000]\n",
    "\n",
    "# precalculo la test_matrix\n",
    "test_matrix <- data.matrix(dataset_test[, campos_buenos, with= FALSE])\n",
    "\n",
    "cat(\"filas\", nrow(dataset_test), \"columnas\", ncol(dataset_test), \"\\n\")\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: DiceKriging\n",
      "\n",
      "Loading required package: mlrMBO\n",
      "\n",
      "Loading required package: mlr\n",
      "\n",
      "Loading required package: ParamHelpers\n",
      "\n",
      "Loading required package: smoof\n",
      "\n",
      "Loading required package: checkmate\n",
      "\n",
      "\n",
      "Attaching package: ‘checkmate’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:DiceKriging’:\n",
      "\n",
      "    checkNames\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# paquetes necesarios para la Bayesian Optimization\n",
    "if(!require(\"DiceKriging\")) install.packages(\"DiceKriging\")\n",
    "require(\"DiceKriging\")\n",
    "\n",
    "if(!require(\"mlrMBO\")) install.packages(\"mlrMBO\")\n",
    "require(\"mlrMBO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Especificacion de la cantidad de iteraciones de la Bayesian Optimization\n",
    "# 50 es razonable\n",
    "PARAM$hipeparametertuning$BO_iteraciones <- 30 # un 50 seria mas razonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# parametros fijos del LightGBM\n",
    "PARAM$lgbm$param_fijos <- list(\n",
    "  objective= \"binary\",\n",
    "  metric= \"custom\",\n",
    "  first_metric_only= TRUE,\n",
    "  boost_from_average= TRUE,\n",
    "  feature_pre_filter= FALSE,\n",
    "  verbosity= -100,\n",
    "  force_row_wise= TRUE, # para evitar warning\n",
    "  seed= PARAM$semilla_primigenia,\n",
    "  extra_trees = FALSE,\n",
    "\n",
    "  max_depth = -1L, # -1 significa no limitar,  por ahora lo dejo fijo\n",
    "  min_gain_to_split = 0.0, # min_gain_to_split >= 0.0\n",
    "  min_sum_hessian_in_leaf = 0.001, #  min_sum_hessian_in_leaf >= 0.0\n",
    "  lambda_l1 = 0.0, # lambda_l1 >= 0.0\n",
    "  lambda_l2 = 0.0, # lambda_l2 >= 0.0\n",
    "\n",
    "  bagging_fraction = 1.0, # 0.0 < bagging_fraction <= 1.0\n",
    "  pos_bagging_fraction = 1.0, # 0.0 < pos_bagging_fraction <= 1.0\n",
    "  neg_bagging_fraction = 1.0, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  is_unbalance = FALSE, #\n",
    "  scale_pos_weight = 1.0, # scale_pos_weight > 0.0\n",
    "\n",
    "  drop_rate = 0.1, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  max_drop = 50, # <=0 means no limit\n",
    "  skip_drop = 0.5, # 0.0 <= skip_drop <= 1.0\n",
    "\n",
    "  max_bin= 31\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Notar que se recorren algunos hiperparametros en forma logaritmica\n",
    "#   y que con forbidden se tiene en cuenta el juego que hay entre min_data_in_leaf y num_leaves\n",
    "\n",
    "PARAM$hipeparametertuning$hs <- makeParamSet(\n",
    "  makeNumericParam(\"num_iterations\", lower= 0.0, upper= 11.1, trafo= function(x) as.integer( round(2^x)) ),\n",
    "  makeNumericParam(\"learning_rate\", lower= -8.0, upper= -1.0, trafo= function(x) 2^x ),\n",
    "  makeNumericParam(\"feature_fraction\", lower= 0.05, upper= 1.0 ),\n",
    "  makeNumericParam(\"min_data_in_leaf\", lower= 0.0, upper= log2(nrow(dtrain)/2), trafo= function(x) as.integer(round(2^x)) ),\n",
    "  makeNumericParam(\"num_leaves\", lower= 1.0, upper= 10.0, trafo= function(x) as.integer(round(2^x)) ),\n",
    "  forbidden= quote( (2^min_data_in_leaf)*(2^num_leaves) > nrow(dtrain) )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El parámetro **ksemillerio** indica se se hace semillerio DENTRO de la bayesiana\n",
    "* 1 **no** se hace Ensemble Semillerio, apenas se corre un solo LightGBM\n",
    "* mayor a 1, se hace un  k-Ensemble Semillerio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El parámetro  **repe** indica si dentro de la bayesiana se toman varias medidas y luego se promedian\n",
    "<br> Esto se hace ya sea que se llama a un solo LightGBM o se haceun Ensemble Semillerio de LightGBMs\n",
    "<br> Tener en cuenta que repe multiplica linealmente el tiempo de corrida de la Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "PARAM$hipeparametertuning$ksemillerio <- 1L\n",
    "PARAM$hipeparametertuning$repe <- 1L\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: primes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if(!require(\"primes\")) install.packages(\"primes\")\n",
    "require(\"primes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "974411"
     ]
    }
   ],
   "source": [
    "primos <- generate_primes(min = 100000, max = 1000000)\n",
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
    "# me quedo con PARAM$semillerio  primos al azar\n",
    "PARAM$BO$semillas <- sample(primos)[seq( PARAM$hipeparametertuning$ksemillerio * PARAM$hipeparametertuning$repe )]\n",
    "\n",
    "cat( PARAM$BO$semillas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: rlist\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if(!require(\"rlist\")) install.packages(\"rlist\")\n",
    "require(\"rlist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# logueo al archivo BO_log.txt\n",
    "loguear  <- function( reg, arch=NA, verbose=TRUE )\n",
    "{\n",
    "  t0 <- Sys.time()\n",
    "  archivo <- arch\n",
    "  if( is.na(arch) ) archivo <- paste0( folder, substitute( reg), ext )\n",
    "\n",
    "\n",
    "  if( !file.exists( archivo ) )\n",
    "  {\n",
    "    # Escribo los titulos\n",
    "    linea  <- paste0( \"fecha\\t\", \n",
    "                      paste( list.names(reg), collapse=\"\\t\" ), \"\\n\" )\n",
    "\n",
    "    cat( linea, file=archivo )\n",
    "  }\n",
    "\n",
    "  # escribo el registro\n",
    "  linea  <- paste0( format(t0, \"%Y%m%d.%H%M%S\"),  \"\\t\",     # la fecha y hora\n",
    "                    gsub( \", \", \"\\t\", toString( reg ) ),  \"\\n\" )\n",
    "\n",
    "  cat( linea, file=archivo, append=TRUE )  # grabo al archivo\n",
    "\n",
    "  if( verbose )  cat( linea )   # imprimo por pantalla\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# esto esta en una funcion para que el garbage collector lo libere\n",
    "# entrena, aplica el modelo a testing, y devuelve el vector de probabilidades\n",
    "\n",
    "OneTrainPredict <- function(param_completo) {\n",
    "    \n",
    "  modelo <- lgb.train(\n",
    "    data= dtrain,\n",
    "    param= param_completo\n",
    "  )\n",
    "  gmodelo <<- modelo\n",
    "\n",
    "  # aplico el modelo a los datos nuevos\n",
    "  pred <- predict(\n",
    "    modelo,\n",
    "    test_matrix\n",
    "  )\n",
    "\n",
    "  return( pred )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# En el argumento x llegan los parmaetros de la bayesiana\n",
    "#  devuelve la ganancia en datos de testing\n",
    "\n",
    "# aqui se ira guardando la mejor iteracion de la bayesiana\n",
    "gmejor <- list()\n",
    "gmejor$iter <- 0\n",
    "gmejor$gan <- -Inf\n",
    "\n",
    "giter <- 0\n",
    "if( file.exists(\"BO_log.txt\") ){\n",
    "  tb_BO <- fread(\"BO_log.txt\")\n",
    "  giter <- nrow(tb_BO) -1 \n",
    "}\n",
    "\n",
    "EstimarGanancia_lightgbm <- function(x) {\n",
    "\n",
    "  giter <<- giter + 1\n",
    "  # x pisa (o agrega) a param_fijos\n",
    "  param_completo <- modifyList(PARAM$lgbm$param_fijos, x)\n",
    "\n",
    "  vgan_mesetas <- c()  # las ganancias, tengo repe de ellas\n",
    "\n",
    "  # loop de las repeticionies\n",
    "  for( repe in seq( PARAM$hipeparametertuning$repe ) )\n",
    "  {\n",
    "     desde <- (PARAM$hipeparametertuning$repe-1)*PARAM$hipeparametertuning$ksemillerio + 1\n",
    "     hasta <- desde + PARAM$hipeparametertuning$ksemillerio -1\n",
    "     rsemillas <- PARAM$BO$semillas[ desde:hasta ]\n",
    "\n",
    "     # vector inicial de probabilidades\n",
    "     vpred_acum <- rep( 0.0, nrow(dataset_test) )\n",
    "\n",
    "     # loop del semillerio\n",
    "     for( sem in rsemillas ) # itero semillerio\n",
    "     {\n",
    "        param_completo$seed <- sem  # asigno se semilla\n",
    "        vpred_acum <- vpred_acum + OneTrainPredict( param_completo )\n",
    "        \n",
    "        gc(full= TRUE, verbose= FALSE)\n",
    "     }\n",
    "\n",
    "     # Calculo de ganancia suavizada de la meseta\n",
    "     tb_prediccion <- dataset_test[, list(gan)]\n",
    "     tb_prediccion[, prob := vpred_acum ]\n",
    "\n",
    "     setorder(tb_prediccion, -prob)\n",
    "     tb_prediccion[, gan_acum := cumsum(gan)]\n",
    "\n",
    "     # la meseta es un punto, mil para la izquierda, otros mil para la derecha\n",
    "     tb_prediccion[, gan_meseta :=\n",
    "       frollmean(\n",
    "         x= gan_acum, n= 2001, align= \"center\",\n",
    "         na.rm= TRUE, hasNA= TRUE\n",
    "      )\n",
    "     ]\n",
    "\n",
    "     vgan_mesetas <- c(vgan_mesetas, tb_prediccion[, max(gan_meseta, na.rm = TRUE)] )\n",
    "  }\n",
    "\n",
    "  gan_mesetas_prom <- mean( vgan_mesetas ) \n",
    "\n",
    "  if( gan_mesetas_prom > gmejor$gan ){\n",
    "    gmejor$gan <<- gan_mesetas_prom\n",
    "    gmejor$iter <<- giter\n",
    "\n",
    "    # hrabo importancia de variables\n",
    "    fwrite( lgb.importance(gmodelo),\n",
    "      file= paste0(\"impo_\", giter, \".txt\"),\n",
    "      sep= \"\\t\"\n",
    "    )\n",
    "  }\n",
    "\n",
    "  # datos qeu voy a loguear\n",
    "  xx <- copy(param_completo)\n",
    "  xx$iter <- giter\n",
    "  xx$metrica_mejor <- gmejor$gan\n",
    "  xx$metrica_sd <- sd(vgan_mesetas)\n",
    "  xx$metrica <- gan_mesetas_prom\n",
    "\n",
    "  loguear( xx, \"BO_log.txt\")\n",
    "  set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")  # le reordeno a mlrMBO\n",
    "\n",
    "  return( gan_mesetas_prom ) #tiempo_corrida) )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-01 13:45:58 EDT\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aqui comienza la configuracion de la Bayesian Optimization\n",
    "#  es compleja la configuracion de una Bayesian Optimization\n",
    "\n",
    "# en este archivo quedan la evolucion binaria de la BO\n",
    "kbayesiana <- \"bayesiana.RDATA\"\n",
    "\n",
    "funcion_optimizar <- EstimarGanancia_lightgbm # la funcion que voy a maximizar\n",
    "\n",
    "configureMlr(show.learner.output= FALSE)\n",
    "\n",
    "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
    "# por favor, no desesperarse por lo complejo\n",
    "\n",
    "obj.fun <- makeSingleObjectiveFunction(\n",
    "  fn= funcion_optimizar, # la funcion que voy a maximizar\n",
    "  minimize= FALSE, # estoy Maximizando la ganancia\n",
    "  noisy= TRUE,\n",
    "  par.set= PARAM$hipeparametertuning$hs, # definido al comienzo del programa\n",
    "  has.simple.signature= FALSE # paso los parametros en una lista\n",
    ")\n",
    "\n",
    "# cada 600 segundos guardo el resultado intermedio\n",
    "ctrl <- makeMBOControl(\n",
    "  save.on.disk.at.time= 600, # se graba cada 600 segundos\n",
    "  save.file.path= kbayesiana\n",
    ") # se graba cada 600 segundos\n",
    "\n",
    "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
    "ctrl <- setMBOControlTermination(\n",
    "  ctrl,\n",
    "  iters= PARAM$hipeparametertuning$BO_iteraciones\n",
    ") # cantidad de iteraciones\n",
    "\n",
    "# defino el método estandar para la creacion de los puntos iniciales,\n",
    "# los \"No Inteligentes\"\n",
    "ctrl <- setMBOControlInfill(ctrl, crit= makeMBOInfillCritEI())\n",
    "\n",
    "# establezco la funcion que busca el maximo\n",
    "surr.km <- makeLearner(\n",
    "  \"regr.km\",\n",
    "  predict.type= \"se\",\n",
    "  covtype= \"matern3_2\",\n",
    "  control= list(trace= TRUE)\n",
    ")\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corrida de la Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# inicio la optimizacion bayesiana, retomando si ya existe\n",
    "# es la celda mas lenta de todo el notebook\n",
    "\n",
    "if (!file.exists(kbayesiana)) {\n",
    "  bayesiana_salida <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
    "} else {\n",
    "  bayesiana_salida <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
    "}\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xp4-Bj3aYI8d"
   },
   "source": [
    "## Produccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las decisiones que se toman para la construccion del modelo final son:\n",
    "* Obviamente los datos donde se aplica el modelo es el mes  {202108} , que no tiene clase\n",
    "* Los positvos son  POS={\"BAJA+1\", \"BAJA+2\"}, esta es una meticulosa decisión.\n",
    "* Se entrena en los treinta meses del intervalo [201901, 202106]\n",
    "* Se realiza undersampling al 10%\n",
    "* Se utilizan los hiperparámetros optimos encontrados en la Bayesian Optimization\n",
    "   * Se escala min_data_in_leaf\n",
    "\n",
    "* Por experimentos en meses anteriores, se decide cortar en los 11000 registros con mayor probabildiad de POS={\"BAJA+1\", \"BAJA+2\"}, , esta es una *enorme* decisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuPfQ7ksjwW3"
   },
   "source": [
    "### Final Training Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "PARAM$train_final$future <- c(202108)\n",
    "\n",
    "PARAM$train_final$training <- c(\n",
    "  202101, 202102, 202103, 202104\n",
    ")\n",
    "\n",
    "PARAM$train_final$undersampling <- 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# se filtran los meses donde se entrena el modelo final\n",
    "dataset_train_final <- dataset[foto_mes %in% PARAM$train_final$training]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Registros cambio las proporciones de POS/NEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Undersampling, van todos los \"BAJA+1\" y \"BAJA+2\" y solo algunos \"CONTINIA\"\n",
    "\n",
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
    "dataset_train_final[, azar := runif(nrow(dataset_train_final))]\n",
    "dataset_train_final[, training := 0L]\n",
    "\n",
    "dataset_train_final[\n",
    "  (azar <= PARAM$train_final$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
    "  training := 1L\n",
    "]\n",
    "\n",
    "dataset_train_final[, azar:= NULL] # elimino la columna azar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# paso la clase a binaria que tome valores {0,1}  enteros\n",
    "#  BAJA+1 y BAJA+2  son  1,   CONTINUA es 0\n",
    "#  a partir de ahora ya NO puedo cortar  por prob(BAJA+2) > 1/40\n",
    "\n",
    "library(data.table)\n",
    "setDT(dataset)\n",
    "\n",
    "dataset_train_final[,\n",
    "  clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\",\"BAJA+1\"), 1L, 0L)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptacion Hiperparametros Optimos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solamente escalo min_data_in_leaf  por  nrow(dataset_train_final) / nrow(dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 1 × 33</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>fecha</th><th scope=col>objective</th><th scope=col>metric</th><th scope=col>first_metric_only</th><th scope=col>boost_from_average</th><th scope=col>feature_pre_filter</th><th scope=col>verbosity</th><th scope=col>force_row_wise</th><th scope=col>seed</th><th scope=col>extra_trees</th><th scope=col>⋯</th><th scope=col>max_bin</th><th scope=col>num_iterations</th><th scope=col>learning_rate</th><th scope=col>feature_fraction</th><th scope=col>min_data_in_leaf</th><th scope=col>num_leaves</th><th scope=col>iter</th><th scope=col>metrica_mejor</th><th scope=col>metrica_sd</th><th scope=col>metrica</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;lgl&gt;</th><th scope=col>&lt;lgl&gt;</th><th scope=col>&lt;lgl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;lgl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;lgl&gt;</th><th scope=col>⋯</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;lgl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>20251101</td><td>binary</td><td>auc</td><td>TRUE</td><td>TRUE</td><td>FALSE</td><td>-100</td><td>TRUE</td><td>974411</td><td>FALSE</td><td>⋯</td><td>31</td><td>2149</td><td>0.003916348</td><td>0.4570216</td><td>231</td><td>1021</td><td>40</td><td>403869625</td><td>NA</td><td>403869625</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 1 × 33\n",
       "\\begin{tabular}{lllllllllllllllllllll}\n",
       " fecha & objective & metric & first\\_metric\\_only & boost\\_from\\_average & feature\\_pre\\_filter & verbosity & force\\_row\\_wise & seed & extra\\_trees & ⋯ & max\\_bin & num\\_iterations & learning\\_rate & feature\\_fraction & min\\_data\\_in\\_leaf & num\\_leaves & iter & metrica\\_mejor & metrica\\_sd & metrica\\\\\n",
       " <dbl> & <chr> & <chr> & <lgl> & <lgl> & <lgl> & <int> & <lgl> & <int> & <lgl> & ⋯ & <int> & <int> & <dbl> & <dbl> & <int> & <int> & <int> & <dbl> & <lgl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 20251101 & binary & auc & TRUE & TRUE & FALSE & -100 & TRUE & 974411 & FALSE & ⋯ & 31 & 2149 & 0.003916348 & 0.4570216 & 231 & 1021 & 40 & 403869625 & NA & 403869625\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 1 × 33\n",
       "\n",
       "| fecha &lt;dbl&gt; | objective &lt;chr&gt; | metric &lt;chr&gt; | first_metric_only &lt;lgl&gt; | boost_from_average &lt;lgl&gt; | feature_pre_filter &lt;lgl&gt; | verbosity &lt;int&gt; | force_row_wise &lt;lgl&gt; | seed &lt;int&gt; | extra_trees &lt;lgl&gt; | ⋯ ⋯ | max_bin &lt;int&gt; | num_iterations &lt;int&gt; | learning_rate &lt;dbl&gt; | feature_fraction &lt;dbl&gt; | min_data_in_leaf &lt;int&gt; | num_leaves &lt;int&gt; | iter &lt;int&gt; | metrica_mejor &lt;dbl&gt; | metrica_sd &lt;lgl&gt; | metrica &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 20251101 | binary | auc | TRUE | TRUE | FALSE | -100 | TRUE | 974411 | FALSE | ⋯ | 31 | 2149 | 0.003916348 | 0.4570216 | 231 | 1021 | 40 | 403869625 | NA | 403869625 |\n",
       "\n"
      ],
      "text/plain": [
       "  fecha    objective metric first_metric_only boost_from_average\n",
       "1 20251101 binary    auc    TRUE              TRUE              \n",
       "  feature_pre_filter verbosity force_row_wise seed   extra_trees ⋯ max_bin\n",
       "1 FALSE              -100      TRUE           974411 FALSE       ⋯ 31     \n",
       "  num_iterations learning_rate feature_fraction min_data_in_leaf num_leaves\n",
       "1 2149           0.003916348   0.4570216        231              1021      \n",
       "  iter metrica_mejor metrica_sd metrica  \n",
       "1 40   403869625     NA         403869625"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# leo el archivo donde quedaron los hiperparametros optimos\n",
    "tb_BO <-  fread(\"BO_log.txt\")\n",
    "setorder( tb_BO, -metrica)  # ordeno por metrica descendente\n",
    "tb_BO[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231 464 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$objective</dt>\n",
       "\t\t<dd>'binary'</dd>\n",
       "\t<dt>$metric</dt>\n",
       "\t\t<dd>'auc'</dd>\n",
       "\t<dt>$first_metric_only</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>$boost_from_average</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>$feature_pre_filter</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$verbosity</dt>\n",
       "\t\t<dd>-100</dd>\n",
       "\t<dt>$force_row_wise</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>$seed</dt>\n",
       "\t\t<dd>974411</dd>\n",
       "\t<dt>$extra_trees</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$max_depth</dt>\n",
       "\t\t<dd>-1</dd>\n",
       "\t<dt>$min_gain_to_split</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>$min_sum_hessian_in_leaf</dt>\n",
       "\t\t<dd>0.001</dd>\n",
       "\t<dt>$lambda_l1</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>$lambda_l2</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>$bagging_fraction</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>$pos_bagging_fraction</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>$neg_bagging_fraction</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>$is_unbalance</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$scale_pos_weight</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>$drop_rate</dt>\n",
       "\t\t<dd>0.1</dd>\n",
       "\t<dt>$max_drop</dt>\n",
       "\t\t<dd>50</dd>\n",
       "\t<dt>$skip_drop</dt>\n",
       "\t\t<dd>0.5</dd>\n",
       "\t<dt>$max_bin</dt>\n",
       "\t\t<dd>31</dd>\n",
       "\t<dt>$num_iterations</dt>\n",
       "\t\t<dd>2149</dd>\n",
       "\t<dt>$learning_rate</dt>\n",
       "\t\t<dd>0.0039163480289649</dd>\n",
       "\t<dt>$feature_fraction</dt>\n",
       "\t\t<dd>0.457021580723424</dd>\n",
       "\t<dt>$min_data_in_leaf</dt>\n",
       "\t\t<dd>464</dd>\n",
       "\t<dt>$num_leaves</dt>\n",
       "\t\t<dd>1021</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$objective] 'binary'\n",
       "\\item[\\$metric] 'auc'\n",
       "\\item[\\$first\\_metric\\_only] TRUE\n",
       "\\item[\\$boost\\_from\\_average] TRUE\n",
       "\\item[\\$feature\\_pre\\_filter] FALSE\n",
       "\\item[\\$verbosity] -100\n",
       "\\item[\\$force\\_row\\_wise] TRUE\n",
       "\\item[\\$seed] 974411\n",
       "\\item[\\$extra\\_trees] FALSE\n",
       "\\item[\\$max\\_depth] -1\n",
       "\\item[\\$min\\_gain\\_to\\_split] 0\n",
       "\\item[\\$min\\_sum\\_hessian\\_in\\_leaf] 0.001\n",
       "\\item[\\$lambda\\_l1] 0\n",
       "\\item[\\$lambda\\_l2] 0\n",
       "\\item[\\$bagging\\_fraction] 1\n",
       "\\item[\\$pos\\_bagging\\_fraction] 1\n",
       "\\item[\\$neg\\_bagging\\_fraction] 1\n",
       "\\item[\\$is\\_unbalance] FALSE\n",
       "\\item[\\$scale\\_pos\\_weight] 1\n",
       "\\item[\\$drop\\_rate] 0.1\n",
       "\\item[\\$max\\_drop] 50\n",
       "\\item[\\$skip\\_drop] 0.5\n",
       "\\item[\\$max\\_bin] 31\n",
       "\\item[\\$num\\_iterations] 2149\n",
       "\\item[\\$learning\\_rate] 0.0039163480289649\n",
       "\\item[\\$feature\\_fraction] 0.457021580723424\n",
       "\\item[\\$min\\_data\\_in\\_leaf] 464\n",
       "\\item[\\$num\\_leaves] 1021\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$objective\n",
       ":   'binary'\n",
       "$metric\n",
       ":   'auc'\n",
       "$first_metric_only\n",
       ":   TRUE\n",
       "$boost_from_average\n",
       ":   TRUE\n",
       "$feature_pre_filter\n",
       ":   FALSE\n",
       "$verbosity\n",
       ":   -100\n",
       "$force_row_wise\n",
       ":   TRUE\n",
       "$seed\n",
       ":   974411\n",
       "$extra_trees\n",
       ":   FALSE\n",
       "$max_depth\n",
       ":   -1\n",
       "$min_gain_to_split\n",
       ":   0\n",
       "$min_sum_hessian_in_leaf\n",
       ":   0.001\n",
       "$lambda_l1\n",
       ":   0\n",
       "$lambda_l2\n",
       ":   0\n",
       "$bagging_fraction\n",
       ":   1\n",
       "$pos_bagging_fraction\n",
       ":   1\n",
       "$neg_bagging_fraction\n",
       ":   1\n",
       "$is_unbalance\n",
       ":   FALSE\n",
       "$scale_pos_weight\n",
       ":   1\n",
       "$drop_rate\n",
       ":   0.1\n",
       "$max_drop\n",
       ":   50\n",
       "$skip_drop\n",
       ":   0.5\n",
       "$max_bin\n",
       ":   31\n",
       "$num_iterations\n",
       ":   2149\n",
       "$learning_rate\n",
       ":   0.0039163480289649\n",
       "$feature_fraction\n",
       ":   0.457021580723424\n",
       "$min_data_in_leaf\n",
       ":   464\n",
       "$num_leaves\n",
       ":   1021\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$objective\n",
       "[1] \"binary\"\n",
       "\n",
       "$metric\n",
       "[1] \"auc\"\n",
       "\n",
       "$first_metric_only\n",
       "[1] TRUE\n",
       "\n",
       "$boost_from_average\n",
       "[1] TRUE\n",
       "\n",
       "$feature_pre_filter\n",
       "[1] FALSE\n",
       "\n",
       "$verbosity\n",
       "[1] -100\n",
       "\n",
       "$force_row_wise\n",
       "[1] TRUE\n",
       "\n",
       "$seed\n",
       "[1] 974411\n",
       "\n",
       "$extra_trees\n",
       "[1] FALSE\n",
       "\n",
       "$max_depth\n",
       "[1] -1\n",
       "\n",
       "$min_gain_to_split\n",
       "[1] 0\n",
       "\n",
       "$min_sum_hessian_in_leaf\n",
       "[1] 0.001\n",
       "\n",
       "$lambda_l1\n",
       "[1] 0\n",
       "\n",
       "$lambda_l2\n",
       "[1] 0\n",
       "\n",
       "$bagging_fraction\n",
       "[1] 1\n",
       "\n",
       "$pos_bagging_fraction\n",
       "[1] 1\n",
       "\n",
       "$neg_bagging_fraction\n",
       "[1] 1\n",
       "\n",
       "$is_unbalance\n",
       "[1] FALSE\n",
       "\n",
       "$scale_pos_weight\n",
       "[1] 1\n",
       "\n",
       "$drop_rate\n",
       "[1] 0.1\n",
       "\n",
       "$max_drop\n",
       "[1] 50\n",
       "\n",
       "$skip_drop\n",
       "[1] 0.5\n",
       "\n",
       "$max_bin\n",
       "[1] 31\n",
       "\n",
       "$num_iterations\n",
       "[1] 2149\n",
       "\n",
       "$learning_rate\n",
       "[1] 0.003916348\n",
       "\n",
       "$feature_fraction\n",
       "[1] 0.4570216\n",
       "\n",
       "$min_data_in_leaf\n",
       "[1] 464\n",
       "\n",
       "$num_leaves\n",
       "[1] 1021\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# en la tabla ademas de los parametros del LightGBM, hay campos de salida\n",
    "param_lgbm <- union( names(PARAM$lgbm$param_fijos),  names(PARAM$hipeparametertuning$hs$pars) )\n",
    "\n",
    "PARAM$train_final$param_mejores <- as.list( tb_BO[1, param_lgbm, with=FALSE])\n",
    "\n",
    "PARAM$train_final$param_mejores$min_data_in_leaf <- as.integer( round(PARAM$train_final$param_mejores$min_data_in_leaf * nrow(dataset_train_final[training == 1L]) / nrow(dtrain)))\n",
    "\n",
    "cat( tb_BO[1, min_data_in_leaf] , PARAM$train_final$param_mejores$min_data_in_leaf, \"\\n\")\n",
    "PARAM$train_final$param_mejores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui SIEMPRE voy a hacer un semillerio, independientemente de si en la Bayesian Optimization calculé un semillerio en cada iteración.\n",
    "<br> Entreno un LightGBM para cada semilla,  y guardo el modelo dentro de la carpeta  **modelitos**\n",
    "<br> Intencionalmente en una primera etapá se generan los modelos y graban, y en una segunda etapa se leen eso modelos y se aplican a los datos del futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Semillerio Final\n",
    "PARAM$train_final$ksemillerio  <- 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>974411</li><li>507673</li><li>696271</li><li>281233</li><li>677309</li><li>180647</li><li>251519</li><li>235241</li><li>176213</li><li>162601</li><li>138637</li><li>519551</li><li>807931</li><li>471301</li><li>152063</li><li>823663</li><li>874337</li><li>466201</li><li>206191</li><li>787939</li><li>361327</li><li>320141</li><li>459847</li><li>246833</li><li>208799</li><li>381371</li><li>868327</li><li>745187</li><li>297371</li><li>244147</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 974411\n",
       "\\item 507673\n",
       "\\item 696271\n",
       "\\item 281233\n",
       "\\item 677309\n",
       "\\item 180647\n",
       "\\item 251519\n",
       "\\item 235241\n",
       "\\item 176213\n",
       "\\item 162601\n",
       "\\item 138637\n",
       "\\item 519551\n",
       "\\item 807931\n",
       "\\item 471301\n",
       "\\item 152063\n",
       "\\item 823663\n",
       "\\item 874337\n",
       "\\item 466201\n",
       "\\item 206191\n",
       "\\item 787939\n",
       "\\item 361327\n",
       "\\item 320141\n",
       "\\item 459847\n",
       "\\item 246833\n",
       "\\item 208799\n",
       "\\item 381371\n",
       "\\item 868327\n",
       "\\item 745187\n",
       "\\item 297371\n",
       "\\item 244147\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 974411\n",
       "2. 507673\n",
       "3. 696271\n",
       "4. 281233\n",
       "5. 677309\n",
       "6. 180647\n",
       "7. 251519\n",
       "8. 235241\n",
       "9. 176213\n",
       "10. 162601\n",
       "11. 138637\n",
       "12. 519551\n",
       "13. 807931\n",
       "14. 471301\n",
       "15. 152063\n",
       "16. 823663\n",
       "17. 874337\n",
       "18. 466201\n",
       "19. 206191\n",
       "20. 787939\n",
       "21. 361327\n",
       "22. 320141\n",
       "23. 459847\n",
       "24. 246833\n",
       "25. 208799\n",
       "26. 381371\n",
       "27. 868327\n",
       "28. 745187\n",
       "29. 297371\n",
       "30. 244147\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 974411 507673 696271 281233 677309 180647 251519 235241 176213 162601\n",
       "[11] 138637 519551 807931 471301 152063 823663 874337 466201 206191 787939\n",
       "[21] 361327 320141 459847 246833 208799 381371 868327 745187 297371 244147"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
    "PARAM$train_final$semillas <- sample(primos)[seq( PARAM$train_final$ksemillerio )]\n",
    "PARAM$train_final$semillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filas 473690 columnas 1253 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-01 17:34:51 EDT\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dejo los datos en formato LightGBM\n",
    "dtrain_final <- lgb.Dataset(\n",
    "  data= data.matrix(dataset_train_final[training == 1L, campos_buenos, with= FALSE]),\n",
    "  label= dataset_train_final[training == 1L, clase01],\n",
    "  free_raw_data= FALSE\n",
    ")\n",
    "\n",
    "cat(\"filas\", nrow(dtrain_final), \"columnas\", ncol(dtrain_final), \"\\n\")\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "xElu4s5W4rX7",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-02 00:42:12 EDT\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# genero los modelitos\n",
    "dir.create( \"modelitos\", showWarnings= FALSE)\n",
    "\n",
    "param_completo <- copy( PARAM$train_final$param_mejores)\n",
    "\n",
    "for( sem in PARAM$train_final$semillas ) {\n",
    "\n",
    "  arch_modelo <- paste0(\"./modelitos/mod_\", sem, \".txt\")\n",
    "  if( !file.exists( arch_modelo ) )\n",
    "  {\n",
    "    param_completo$seed <- sem\n",
    "\n",
    "    modelito <- lgb.train(\n",
    "      data= dtrain_final,\n",
    "      param= param_completo\n",
    "    )\n",
    "\n",
    "    lgb.save( modelito, filename= arch_modelo)\n",
    "    rm(modelito)\n",
    "     gc()\n",
    "  }\n",
    "}\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace el predict() del modelo en los datos del futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-02 00:49:19 EDT\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# aplico el modelo a los datos sin clase\n",
    "dfuture <- dataset[foto_mes %in% PARAM$train_final$future ]\n",
    "mfuture <- data.matrix(dfuture[, campos_buenos, with= FALSE])\n",
    "\n",
    "vpred_acum <- rep(0.0, nrow(dfuture))\n",
    "qacumulados <- 0\n",
    "\n",
    "for( sem in PARAM$train_final$semillas ) {\n",
    "\n",
    "  arch_modelo <- paste0(\"./modelitos/mod_\", sem, \".txt\")\n",
    "  if( file.exists( arch_modelo ) )\n",
    "  {\n",
    "    modelo_final <- lgb.load(arch_modelo) # leo del disco\n",
    "    #hago el predict() y acumulo\n",
    "    vpred_acum <- vpred_acum + predict(modelo_final, mfuture)\n",
    "    qacumulados <- qacumulados + 1\n",
    "  }\n",
    "}\n",
    "\n",
    "vpred_acum <- vpred_acum / qacumulados  # paso a probabildiad\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "RJwg7LHd11yu",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# tabla de prediccion, puede ser util para futuros ensembles\n",
    "#  ya que le modelo ganador va a ser un ensemble de LightGBMs\n",
    "\n",
    "tb_prediccion <- dfuture[, list(numero_de_cliente, foto_mes)]\n",
    "tb_prediccion[, prob := vpred_acum ]\n",
    "\n",
    "# grabo las probabilidad del modelo\n",
    "fwrite(tb_prediccion,\n",
    "  file= \"prediccion.txt\",\n",
    "  sep= \"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOt4eG_55ltv"
   },
   "source": [
    "### Clasificacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tomó la decisión de enviar a los 11000 registros con mayor probabilidad de POS={\"BAJA+1\",\"BAJA+\"}\n",
    "<br> esto se determinó en forma artesanal analizando meses anterior\n",
    "<br> esta es una muy importante decisión "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "gWW3tatE12je",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# genero archivos con los  \"envios\" mejores\n",
    "dir.create(\"kaggle\", showWarnings=FALSE)\n",
    "\n",
    "# ordeno por probabilidad descendente\n",
    "setorder(tb_prediccion, -prob)\n",
    "\n",
    "envios <- 11000\n",
    "tb_prediccion[, Predicted := 0L] # seteo inicial a 0\n",
    "tb_prediccion[1:envios, Predicted := 1L] # marco los primeros\n",
    "\n",
    "archivo_kaggle <- paste0(\"./kaggle/KA\", PARAM$experimento, \"_\", envios, \".csv\")\n",
    "\n",
    "# grabo el archivo\n",
    "fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
    "  file= archivo_kaggle,\n",
    "  sep= \",\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "9zA_W25c15DP",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-02 00:49:19 EDT\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Sys.time()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
